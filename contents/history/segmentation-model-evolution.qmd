---
title: "The Evolution of Segmentation Models: A Historical Tour"
---

Excellent choice! Segmentation is **critical for radiology AI** â€” it's how we delineate organs, tumors, and anatomical structures. Let's journey through its evolution.


## ğŸ¯ What is Segmentation?

```
    CLASSIFICATION vs SEGMENTATION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    CLASSIFICATION                      SEGMENTATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Input:                              Input:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚                 â”‚                 â”‚
    â”‚    ğŸ«  Lung     â”‚                 â”‚    ğŸ«  Lung     â”‚
    â”‚                 â”‚                 â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                   â”‚
            â–¼                                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚                 â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
    â”‚  "Lung X-ray"   â”‚                 â”‚â–‘â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â”‚
    â”‚                 â”‚                 â”‚â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚â–‘â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â”‚
                                        â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
    Output: Single label                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        
                                        Output: Label for EVERY pixel
                                        â–‘ = Background
                                        â–“ = Lung tissue
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Types of Segmentation:**

```
    SEGMENTATION TAXONOMY
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. SEMANTIC SEGMENTATION
       "What class is each pixel?"
       
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  ğŸš—    ğŸš—       â”‚              â”‚  â–“â–“    â–“â–“       â”‚  All cars = same color
       â”‚      ğŸš¶        â”‚     â”€â”€â”€â–º     â”‚      â–‘â–‘        â”‚  All people = same color
       â”‚  ğŸŒ³    ğŸš—      â”‚              â”‚  â–ˆâ–ˆ    â–“â–“      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    2. INSTANCE SEGMENTATION
       "What class AND which individual?"
       
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  ğŸš—    ğŸš—       â”‚              â”‚  â–“â–“    â–ˆâ–ˆ       â”‚  Car 1 â‰  Car 2
       â”‚      ğŸš¶        â”‚     â”€â”€â”€â–º     â”‚      â–‘â–‘        â”‚  Each instance unique!
       â”‚  ğŸŒ³    ğŸš—      â”‚              â”‚  â–’â–’    â–“â–“      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    3. PANOPTIC SEGMENTATION
       "Semantic + Instance combined"
       
       Combines both: Every pixel labeled + instances distinguished
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    IN RADIOLOGY:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Semantic:  "Segment all tumor tissue"    (doesn't distinguish tumors)
    Instance:  "Segment each tumor separately" (tumor 1, tumor 2, ...)
    
    Example - Liver CT:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
    â”‚     â”‚ Liver   â”‚         â”‚    Semantic: Liver vs Lesion (2 classes)
    â”‚     â”‚  â”Œâ”€â”€â”   â”‚         â”‚
    â”‚     â”‚  â”‚L1â”‚   â”‚         â”‚    Instance: Liver + Lesion1 + Lesion2
    â”‚     â”‚  â””â”€â”€â”˜â”Œâ”€â”€â”         â”‚              (each lesion tracked)
    â”‚     â”‚      â”‚L2â”‚         â”‚
    â”‚     â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”˜         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


## ğŸ›ï¸ Era 1: Classical Methods (Pre-Deep Learning)

Before deep learning, radiologists and researchers used these techniques:

```
    CLASSICAL SEGMENTATION METHODS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. THRESHOLDING (simplest)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Original Image          Histogram              Thresholded
    (grayscale)                                    
                               â”‚                   
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â–“â–“â”‚    â–“â–“             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚â–‘â–‘â–‘â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â”‚        â–“â–“â”‚    â–“â–“             â”‚â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
    â”‚â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â”‚        â–“â–“â”‚â–“â–“  â–“â–“             â”‚â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
    â”‚â–‘â–‘â–‘â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â”‚        â–“â–“â”‚â–“â–“â–“â–“â–“â–“             â”‚â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â–º          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            0  T     255           
                               â†‘                   if pixel > T: white
                           threshold               else: black
    
    Limitation: Only works with clear intensity differences
                (fails in noisy medical images!)
    
    
    2. REGION GROWING
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Start with seed point, grow by adding similar neighbors
    
    Step 1:        Step 2:        Step 3:        Final:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚    â”‚    â–‘    â”‚    â”‚   â–‘â–‘â–‘   â”‚    â”‚  â–‘â–‘â–‘â–‘â–‘  â”‚
    â”‚    â€¢    â”‚    â”‚   â–‘â–‘â–‘   â”‚    â”‚  â–‘â–‘â–‘â–‘â–‘  â”‚    â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚
    â”‚         â”‚    â”‚    â–‘    â”‚    â”‚  â–‘â–‘â–‘â–‘â–‘  â”‚    â”‚  â–‘â–‘â–‘â–‘â–‘  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        seed        expand         expand          stop
    
    Limitation: Sensitive to seed selection, leaks through weak boundaries
    
    
    3. WATERSHED ALGORITHM
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Treat image as topographic surface, flood from minima
    
            â•±â•²        â•±â•²
           â•±  â•²      â•±  â•²
          â•±    â•²    â•±    â•²
         â•±      â•²__â•±      â•²        Water fills "basins"
        â•±    ğŸ’§      ğŸ’§    â•²       Watershed lines = boundaries
       â•±____________________ â•²
       
    Good for: Cell segmentation in microscopy
    Limitation: Over-segmentation
    
    
    4. ACTIVE CONTOURS (Snakes)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Energy-minimizing curve that wraps around objects
    
    Initial:               Iterating:              Final:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚    â”Œâ”€â”€â”€â”€â”€â”    â”‚      â”‚      â•­â”€â”€â”€â•®    â”‚
    â”‚  â”‚         â”‚  â”‚      â”‚   â•±       â•²   â”‚      â”‚     â•±     â•²   â”‚
    â”‚  â”‚    â–“â–“   â”‚  â”‚  â”€â”€â–º â”‚  â”‚   â–“â–“    â”‚  â”‚  â”€â”€â–º â”‚    â”‚  â–“â–“   â”‚  â”‚
    â”‚  â”‚   â–“â–“â–“â–“  â”‚  â”‚      â”‚   â•²  â–“â–“â–“â–“ â•±   â”‚      â”‚     â•²â–“â–“â–“â–“ â•±   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚    â””â”€â”€â”€â”€â”€â”˜    â”‚      â”‚      â•°â”€â”€â”€â•¯    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Energy = Internal (smoothness) + External (image edges)
    
    Limitation: Requires good initialization, struggles with complex shapes
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ”„ Era 2: Fully Convolutional Networks - FCN (2014)

**The Deep Learning Revolution for Segmentation**

Jonathan Long, Evan Shelhamer, and Trevor Darrell introduced FCN.

```
    THE PROBLEM: CNNs output a single label
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Classification CNN (e.g., VGG):
    
    Input          Conv layers              FC layers         Output
    224Ã—224        progressively            flatten           
                   downsample                                 
                                                              
    â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”
    â”‚      â”‚      â”‚    â”‚  â”‚   â”‚  â”‚  â”‚      â”‚â€¢ â€¢ â€¢ â€¢ â€¢â”‚      â”‚   â”‚
    â”‚Image â”‚ â”€â”€â–º  â”‚    â”‚â”€â–ºâ”‚   â”‚â”€â–ºâ”‚  â”‚ â”€â”€â–º  â”‚â€¢ â€¢ â€¢ â€¢ â€¢â”‚ â”€â”€â–º  â”‚ ğŸ±â”‚
    â”‚      â”‚      â”‚    â”‚  â”‚   â”‚  â”‚  â”‚      â”‚â€¢ â€¢ â€¢ â€¢ â€¢â”‚      â”‚   â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”˜
    224Ã—224       112     56     28         Flattened        1 label
                  Ã—112    Ã—56    Ã—28        vector
    
    
    SPATIAL INFORMATION IS LOST! 
    We can't tell WHERE the cat is, only THAT there's a cat.
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**FCN Solution: Replace FC layers with Convolutions**

```
    FULLY CONVOLUTIONAL NETWORK (FCN)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Key Insight: 1Ã—1 convolutions can replace fully connected layers!
    
    
    FC Layer:                           1Ã—1 Convolution:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â”‚                     â”‚ â”Œâ”€â”€â”€â”     â”‚
    â”‚ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â”‚  â—„â”€â”€ equivalent â”€â”€â–º â”‚ â”‚1Ã—1â”‚     â”‚
    â”‚ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â”‚      to             â”‚ â”‚   â”‚     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ â””â”€â”€â”€â”˜     â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    All-to-all connections              Preserves spatial dims!
    
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    FCN ARCHITECTURE:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Input         Encoder (Downsampling)              Decoder (Upsampling)      Output
    
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                                                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”      â”‚  â”Œâ”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”    â”Œâ”€â”                          â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚      â”‚      â”‚  â”‚    â”‚    â”‚   â”‚    â”‚  â”‚    â”‚ â”‚    Upsample              â”‚   â”‚â–“â–“â–‘â–‘â–‘â–‘â”‚
    â”‚ IMG  â”‚â”€â”€â”€â”€â”€â”€â”¼â”€â–ºâ”‚    â”‚â”€â”€â”€â–ºâ”‚   â”‚â”€â”€â”€â–ºâ”‚  â”‚â”€â”€â”€â–ºâ”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–ºâ”‚â–“â–“â–“â–‘â–‘â–‘â”‚
    â”‚      â”‚      â”‚  â”‚    â”‚    â”‚   â”‚    â”‚  â”‚    â”‚ â”‚    (Deconvolution/        â”‚   â”‚â–‘â–“â–“â–“â–‘â–‘â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜      â”‚  â””â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”˜    â””â”€â”€â”˜    â””â”€â”˜     Transposed Conv)      â”‚   â””â”€â”€â”€â”€â”€â”€â”˜
    H Ã— W         â”‚  H/2       H/4      H/8    H/16                           â”‚   H Ã— W
                  â”‚                                                          â”‚   C classes
                  â”‚  Feature maps get smaller but deeper (more channels)     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    UPSAMPLING METHODS:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. Bilinear Interpolation (fixed)
    
       â”Œâ”€â”€â”€â”¬â”€â”€â”€â”         â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
       â”‚ 1 â”‚ 3 â”‚         â”‚ 1 â”‚ 2 â”‚ 2 â”‚ 3 â”‚
       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¤   â”€â”€â–º   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
       â”‚ 2 â”‚ 4 â”‚         â”‚1.5â”‚2.5â”‚2.5â”‚3.5â”‚
       â””â”€â”€â”€â”´â”€â”€â”€â”˜         â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
                         â”‚1.5â”‚2.5â”‚2.5â”‚3.5â”‚
         2Ã—2             â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
                         â”‚ 2 â”‚ 3 â”‚ 3 â”‚ 4 â”‚
                         â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
                               4Ã—4
    
    
    2. Transposed Convolution (learnable) - also called "Deconvolution"
    
       Input    Kernel        Output
        2Ã—2      3Ã—3           4Ã—4
       
       â”Œâ”€â”€â”€â”¬â”€â”€â”€â”              â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
       â”‚ 1 â”‚ 2 â”‚   â•³   K  =   â”‚   â”‚   â”‚   â”‚   â”‚
       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¤              â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
       â”‚ 3 â”‚ 4 â”‚              â”‚   â”‚   â”‚   â”‚   â”‚
       â””â”€â”€â”€â”´â”€â”€â”€â”˜              â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
                              â”‚   â”‚   â”‚   â”‚   â”‚
       Each input value       â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
       "stamps" the kernel    â”‚   â”‚   â”‚   â”‚   â”‚
       onto output            â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**FCN Variants with Skip Connections:**

```
    FCN-32s vs FCN-16s vs FCN-8s
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    The number indicates stride of final prediction
    
    
    FCN-32s (coarse):
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Pool3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    Pool4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
    Pool5 â”€â”€â”€â”€â”€â–º 1Ã—1 conv â”€â”€â”€â”€â”€â–º 32Ã— upsample â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â–º Output
                                                            â”‚
                                 Coarse! Loses detail       â”‚
                                                            â”‚
                                                            â”‚
    FCN-8s (fine):                                          â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
                                                            â”‚
    Pool3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º 1Ã—1 conv â”€â”€â”           â”‚
                                                â”‚           â”‚
    Pool4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º 1Ã—1 conv â”€â”€â”              â”‚           â”‚
                                 â”‚    2Ã— up     â”‚           â”‚
    Pool5 â”€â–º 1Ã—1 â”€â–º 2Ã— up â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â–º + â”€â”€â”€â”€â”´â”€â”€â”€â–º 8Ã— up â”€â–º Out
                                     
                                 Fuse multi-scale features!
                                 Much better boundaries!
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    Visual comparison:
    
    Ground Truth        FCN-32s            FCN-8s
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â•­â”€â”€â”€â•®   â”‚      â”‚   â–“â–“â–“â–“    â”‚      â”‚   â•­â”€â”€â”€â•®   â”‚
    â”‚  â•±     â•²  â”‚      â”‚  â–“â–“â–“â–“â–“â–“   â”‚      â”‚  â•±     â•²  â”‚
    â”‚ â”‚       â”‚ â”‚      â”‚  â–“â–“â–“â–“â–“â–“   â”‚      â”‚ â”‚       â”‚ â”‚
    â”‚  â•²     â•±  â”‚      â”‚   â–“â–“â–“â–“    â”‚      â”‚  â•²     â•±  â”‚
    â”‚   â•°â”€â”€â”€â•¯   â”‚      â”‚           â”‚      â”‚   â•°â”€â”€â”€â•¯   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Sharp edges         Blocky!            Much better!
```


## ğŸ† Era 3: U-Net â€” The Medical Imaging Champion (2015)

**The Most Influential Architecture in Medical Image Segmentation**

Olaf Ronneberger introduced U-Net for biomedical image segmentation.

```
    U-NET ARCHITECTURE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
                            The "U" Shape
    
    Input                                                              Output
    572Ã—572                                                            388Ã—388
       â”‚                                                                  â–²
       â–¼                                                                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”                                                          â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚ 64ch â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ 64ch â”‚
    â””â”€â”€â”¬â”€â”€â”€â”˜                     copy & crop                          â””â”€â”€â–²â”€â”€â”€â”˜
       â”‚ â†“ maxpool                                                       â”‚ â†‘ up-conv
    â”Œâ”€â”€â–¼â”€â”€â”€â”                                                          â”Œâ”€â”€â”´â”€â”€â”€â”
    â”‚128ch â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚128ch â”‚
    â””â”€â”€â”¬â”€â”€â”€â”˜                     copy & crop                          â””â”€â”€â–²â”€â”€â”€â”˜
       â”‚ â†“                                                               â”‚ â†‘
    â”Œâ”€â”€â–¼â”€â”€â”€â”                                                          â”Œâ”€â”€â”´â”€â”€â”€â”
    â”‚256ch â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚256ch â”‚
    â””â”€â”€â”¬â”€â”€â”€â”˜                     copy & crop                          â””â”€â”€â–²â”€â”€â”€â”˜
       â”‚ â†“                                                               â”‚ â†‘
    â”Œâ”€â”€â–¼â”€â”€â”€â”                                                          â”Œâ”€â”€â”´â”€â”€â”€â”
    â”‚512ch â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚512ch â”‚
    â””â”€â”€â”¬â”€â”€â”€â”˜                     copy & crop                          â””â”€â”€â–²â”€â”€â”€â”˜
       â”‚ â†“                                                               â”‚ â†‘
       â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚1024ch  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚Bottleneck                              
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
         ENCODER                                              DECODER
         (Contracting Path)                                   (Expanding Path)
         - Extract features                                   - Localize features
         - Increase channels                                  - Restore resolution
         - Decrease resolution                                - Decrease channels
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**The Key Innovation: Skip Connections**

```
    WHY SKIP CONNECTIONS MATTER
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Problem: Deep networks lose fine spatial details
    
    
    Without Skip Connections:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    High-res input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Low-res output
                          â”‚
                          â–¼
                    Bottleneck
                    (compressed)
                          â”‚
                    Fine details LOST!
                    Only "what" remains,
                    not "where exactly"
    
    
    With Skip Connections (U-Net):
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    High-res features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Concatenate!
                                        â”‚                          â”‚
                          â”‚             â”‚                          â”‚
                          â–¼             â”‚                          â–¼
                    Bottleneck          â”‚              Fine details PRESERVED!
                    (semantic info)     â”‚              "what" + "where" combined
                          â”‚             â”‚
                          â–¼             â”‚
                    Upsampled â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    CONCATENATION vs ADDITION:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    FCN (ResNet-style):              U-Net:
    
    Encoder feature                  Encoder feature
         â”‚                                â”‚
         â–¼                                â–¼
       [ + ] â—„â”€â”€ Decoder             [concat] â—„â”€â”€ Decoder
         â”‚       feature                  â”‚        feature
         â–¼                                â–¼
      Same channels                 Doubled channels!
      (sum the info)               (preserve all info)
    
    
    U-Net preserves MORE information by concatenating,
    allowing the network to learn what to use from each path.
```

**U-Net Block Details:**

```
    ENCODER BLOCK                          DECODER BLOCK
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Input                                  Skip connection
      â”‚                                         â”‚
      â–¼                                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Conv 3Ã—3    â”‚                        â”‚ Up-conv 2Ã—2 â”‚ (or UpSample + Conv)
    â”‚ BatchNorm   â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
    â”‚ ReLU        â”‚                               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â–¼
    â”‚ Conv 3Ã—3    â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚ BatchNorm   â”‚                        â”‚  Concatenate â”‚ â—„â”€â”€ From encoder
    â”‚ ReLU        â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                               â”‚
           â”‚                                      â–¼
           â–¼                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚ Conv 3Ã—3    â”‚
    â”‚ MaxPool 2Ã—2 â”‚                        â”‚ BatchNorm   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â”‚ ReLU        â”‚
           â”‚                               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           â–¼                               â”‚ Conv 3Ã—3    â”‚
    To next encoder                        â”‚ BatchNorm   â”‚
    block                                  â”‚ ReLU        â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                           To next decoder
                                           block
```


## ğŸ¥ Era 3.5: Medical Imaging Variants (2016-2020)

U-Net spawned many variants optimized for medical imaging:

```
    U-NET FAMILY TREE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
                              U-Net (2015)
                                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                     â”‚                     â”‚
            â–¼                     â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   V-Net       â”‚    â”‚  3D U-Net     â”‚    â”‚ Attention     â”‚
    â”‚   (2016)      â”‚    â”‚  (2016)       â”‚    â”‚ U-Net (2018)  â”‚
    â”‚               â”‚    â”‚               â”‚    â”‚               â”‚
    â”‚ â€¢ Volumetric  â”‚    â”‚ â€¢ Full 3D     â”‚    â”‚ â€¢ Attention   â”‚
    â”‚ â€¢ Dice loss   â”‚    â”‚   convolutionsâ”‚    â”‚   gates       â”‚
    â”‚ â€¢ Residual    â”‚    â”‚ â€¢ Memory      â”‚    â”‚ â€¢ Focus on    â”‚
    â”‚   connections â”‚    â”‚   intensive   â”‚    â”‚   relevant    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   regions     â”‚
            â”‚                     â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚                     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   nnU-Net (2021)  â”‚
                        â”‚                   â”‚
                        â”‚ â€¢ Self-configuringâ”‚
                        â”‚ â€¢ Auto preprocessing
                        â”‚ â€¢ State-of-the-artâ”‚
                        â”‚   out of the box  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**V-Net: For Volumetric Medical Images (CT/MRI)**

```
    V-NET FOR 3D SEGMENTATION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Input: 3D Volume (e.g., CT scan)
    
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â•±             â•±â”‚
         â•±             â•± â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     Depth (slices)
        â”‚             â”‚  â”‚        â”‚
        â”‚   Volume    â”‚  â”‚        â”‚
        â”‚             â”‚ â•±         â–¼
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â•±
              â”‚
              â–¼
    
    Instead of 2D Conv:          Use 3D Conv:
    
    â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”               â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
    â”‚ â€¢ â”‚ â€¢ â”‚ â€¢ â”‚               â”‚ â€¢ â”‚ â€¢ â”‚ â€¢ â”‚â•²
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤               â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤ â•²
    â”‚ â€¢ â”‚ â€¢ â”‚ â€¢ â”‚               â”‚ â€¢ â”‚ â€¢ â”‚ â€¢ â”‚  â”‚
    â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤               â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”‚
    â”‚ â€¢ â”‚ â€¢ â”‚ â€¢ â”‚               â”‚ â€¢ â”‚ â€¢ â”‚ â€¢ â”‚ â•±
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜               â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜â•±
       3Ã—3 kernel                  3Ã—3Ã—3 kernel
    
    
    Key Innovation: DICE LOSS
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
                    2 Ã— |A âˆ© B|
    Dice Score = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    |A| + |B|
    
    
                    Prediction          Ground Truth
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  â–‘â–‘â–‘â–‘   â”‚         â”‚   â–‘â–‘â–‘   â”‚
                    â”‚ â–‘â–‘â–‘â–‘â–‘â–‘  â”‚    âˆ©    â”‚  â–‘â–‘â–‘â–‘â–‘  â”‚
                    â”‚  â–‘â–‘â–‘â–‘   â”‚         â”‚  â–‘â–‘â–‘â–‘   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Dice Loss = 1 - Dice Score
    
    Why Dice? Handles class imbalance!
    (Small tumors vs large background)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Attention U-Net:**

```
    ATTENTION GATE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Problem: Skip connections pass ALL encoder features,
             including irrelevant background
    
    Solution: Learn which features to pass through!
    
    
                          Gating signal
                          (from decoder)
                               â”‚
                               â–¼
    Skip connection â”€â”€â”€â”€â”€â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    (from encoder)          â”‚  Attention  â”‚ â”€â”€â”€â”€â”€â”€â–º Weighted features
                            â”‚    Gate     â”‚         (relevant only!)
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    Attention Gate Detail:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Encoder feature (x)                 Gating signal (g)
    [high resolution]                   [semantic info]
           â”‚                                   â”‚
           â–¼                                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  W_x (1Ã—1)  â”‚                     â”‚  W_g (1Ã—1)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    +    â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ReLU   â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Ïˆ (1Ã—1) â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Sigmoid â”‚ â”€â”€â”€â”€â”€â”€â–º Î± (attention weights)
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         0 to 1 for each location
                         â”‚
                         â–¼
                    x Ã— Î± = attended features
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ”¬ Era 4: DeepLab Series (2014-2018)

**Dilated/Atrous Convolutions for Multi-Scale Features**

```
    THE RESOLUTION PROBLEM
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Standard CNNs downsample aggressively:
    
    Input        After pooling layers      After more pooling
    512Ã—512      256Ã—256 â†’ 128Ã—128 â†’       64Ã—64 â†’ 32Ã—32 â†’ 16Ã—16
    
    Resolution lost! Hard to recover fine boundaries.
    
    
    Solution: DILATED (ATROUS) CONVOLUTIONS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Standard 3Ã—3 Conv:           Dilated Conv (rate=2):        Rate=4:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚          â”‚                     â”‚       â”‚                     â”‚
    â”‚  â— â— â—          â”‚          â”‚  â—   â—   â—         â”‚       â”‚  â—       â—       â— â”‚
    â”‚  â— â— â—          â”‚          â”‚                     â”‚       â”‚                     â”‚
    â”‚  â— â— â—          â”‚          â”‚  â—   â—   â—         â”‚       â”‚                     â”‚
    â”‚                 â”‚          â”‚                     â”‚       â”‚  â—       â—       â— â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â—   â—   â—         â”‚       â”‚                     â”‚
                                 â”‚                     â”‚       â”‚                     â”‚
    Receptive field: 3Ã—3        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â—       â—       â— â”‚
                                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 Receptive field: 5Ã—5         
                                 (with gaps!)                  Receptive field: 9Ã—9
                                                               Same # params as 3Ã—3!
    
    
    Key Insight: Larger receptive field WITHOUT losing resolution
                 or adding parameters!
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**ASPP: Atrous Spatial Pyramid Pooling**

```
    ATROUS SPATIAL PYRAMID POOLING (ASPP)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Capture multi-scale context simultaneously!
    
    
                              Input Feature Map
                                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚            â”‚           â”‚           â”‚            â”‚
            â–¼            â–¼           â–¼           â–¼            â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  1Ã—1    â”‚  â”‚ 3Ã—3     â”‚ â”‚ 3Ã—3     â”‚ â”‚ 3Ã—3     â”‚  â”‚ Global  â”‚
       â”‚  Conv   â”‚  â”‚ rate=6  â”‚ â”‚ rate=12 â”‚ â”‚ rate=18 â”‚  â”‚ AvgPool â”‚
       â”‚         â”‚  â”‚         â”‚ â”‚         â”‚ â”‚         â”‚  â”‚ + 1Ã—1   â”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
            â”‚            â”‚           â”‚           â”‚            â”‚
            â”‚      Fine   â”‚    Medium â”‚   Large   â”‚     Global â”‚
            â”‚     detail  â”‚   context â”‚  context  â”‚    context â”‚
            â”‚            â”‚           â”‚           â”‚            â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ Concatenate â”‚
                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  1Ã—1 Conv   â”‚
                              â”‚  (fuse)     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                              Output Feature Map
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ­ Era 5: Instance Segmentation â€” Mask R-CNN (2017)

**When You Need to Distinguish Individual Objects**

```
    MASK R-CNN PIPELINE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Input Image
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        BACKBONE (ResNet + FPN)                          â”‚
    â”‚                                                                         â”‚
    â”‚  Extract multi-scale features                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     REGION PROPOSAL NETWORK (RPN)                       â”‚
    â”‚                                                                         â”‚
    â”‚  "Where might objects be?"  â†’  Generate ~1000 region proposals          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚    For each proposal:
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         ROI ALIGN                                       â”‚
    â”‚                                                                         â”‚
    â”‚  Extract fixed-size features for each region (7Ã—7 or 14Ã—14)             â”‚
    â”‚  (Better than ROI Pooling - no quantization!)                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                      â”‚                      â”‚
         â–¼                      â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Class  â”‚          â”‚   Box    â”‚          â”‚   Mask   â”‚
    â”‚   Head   â”‚          â”‚   Head   â”‚          â”‚   Head   â”‚
    â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
    â”‚ "What?"  â”‚          â”‚ "Where?" â”‚          â”‚ "Shape?" â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                     â”‚
         â–¼                     â–¼                     â–¼
       Class               Bounding              28Ã—28
      Scores                 Box                  Mask
    
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    OUTPUT EXAMPLE:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                         â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚    â”‚ Person 1    â”‚    â”‚ Person 2    â”‚   â”‚
    â”‚    â”‚ â–“â–“â–“         â”‚    â”‚    â–“â–“â–“     â”‚   â”‚
    â”‚    â”‚â–“â–“â–“â–“â–“        â”‚    â”‚   â–“â–“â–“â–“â–“    â”‚   â”‚
    â”‚    â”‚ â–“â–“â–“         â”‚    â”‚    â–“â–“â–“     â”‚   â”‚
    â”‚    â”‚â–“â–“ â–“â–“        â”‚    â”‚   â–“â–“ â–“â–“    â”‚   â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Each instance gets:
    â€¢ Class label (person)
    â€¢ Bounding box
    â€¢ Pixel-wise mask
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Medical Application: Multi-Lesion Detection**

```
    INSTANCE SEGMENTATION IN RADIOLOGY
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Use Case: Detect and segment multiple liver lesions
    
    
    Input CT Slice:                    Output:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚    â”‚ Liver   â”‚      â”‚            â”‚    â”‚ Liver   â”‚      â”‚
    â”‚    â”‚         â”‚      â”‚            â”‚    â”‚         â”‚      â”‚
    â”‚    â”‚ â€¢    â€¢  â”‚      â”‚            â”‚    â”‚ â–“â–“   â–ˆâ–ˆ â”‚      â”‚
    â”‚    â”‚    â€¢    â”‚      â”‚            â”‚    â”‚    â–‘â–‘   â”‚      â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚            â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
    â”‚                     â”‚            â”‚                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
       Raw CT image                    Lesion 1: â–“â–“ (HCC, 2.3cm)
                                       Lesion 2: â–ˆâ–ˆ (Metastasis, 1.1cm)
                                       Lesion 3: â–‘â–‘ (Cyst, 0.8cm)
    
    Each lesion tracked separately for:
    â€¢ Longitudinal follow-up
    â€¢ Treatment response assessment
    â€¢ Tumor burden calculation
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ¤– Era 6: Transformer-Based Segmentation (2020-Present)

**Bringing Attention to Segmentation**

```
    TRANSFORMER SEGMENTATION EVOLUTION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    2020    SETR (Segmentation Transformer)
            â”‚
            â”‚  Pure Vision Transformer encoder
            â”‚  + CNN decoder
            â”‚
    2021    â”œâ”€â”€â–º SegFormer
            â”‚    â”‚
            â”‚    â”‚  Efficient hierarchical transformer
            â”‚    â”‚  No positional encoding needed
            â”‚    â”‚
            â”œâ”€â”€â–º Swin-UNet
            â”‚    â”‚
            â”‚    â”‚  Swin Transformer + U-shaped architecture
            â”‚    â”‚  Shifted windows for efficiency
            â”‚    â”‚
            â”œâ”€â”€â–º TransUNet
                 â”‚
                 â”‚  CNN encoder + Transformer + U-Net decoder
                 â”‚  Best of both worlds!
    
    2023    Segment Anything Model (SAM)
            â”‚
            â”‚  Foundation model for segmentation
            â”‚  Promptable (click, box, text)
            â”‚  Zero-shot generalization
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**TransUNet: Hybrid Architecture for Medical Imaging**

```
    TRANSUNET ARCHITECTURE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Key Idea: CNN extracts local features, Transformer captures global context
    
    
    Input Image (H Ã— W)
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        CNN ENCODER (ResNet)                             â”‚
    â”‚                                                                         â”‚
    â”‚   Extract hierarchical features with spatial inductive bias             â”‚
    â”‚   H/4 Ã— W/4 Ã— 256  â†’  H/8 Ã— W/8 Ã— 512  â†’  H/16 Ã— W/16 Ã— 1024           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Feature map H/16 Ã— W/16
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                      PATCH EMBEDDING                                    â”‚
    â”‚                                                                         â”‚
    â”‚   Flatten spatial dims into sequence of patches                         â”‚
    â”‚   (H/16 Ã— W/16) patches â†’ sequence for Transformer                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   TRANSFORMER ENCODER                                   â”‚
    â”‚                                                                         â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚  Multi-Head Self-Attention                                      â”‚   â”‚
    â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”                             â”‚   â”‚
    â”‚   â”‚  â”‚Head1â”‚  â”‚Head2â”‚  â”‚Head3â”‚  â”‚ ... â”‚   Global context!           â”‚   â”‚
    â”‚   â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜                             â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                              â”‚                                          â”‚
    â”‚                              â–¼                                          â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚  Feed-Forward Network                                           â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                         â”‚
    â”‚   Ã— 12 layers                                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Reshape back to H/16 Ã— W/16
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     U-NET DECODER                                       â”‚
    â”‚                                                                         â”‚
    â”‚   Progressive upsampling with skip connections from CNN encoder         â”‚
    â”‚   H/16 â†’ H/8 â†’ H/4 â†’ H/2 â†’ H                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Segmentation Output (H Ã— W Ã— C)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Segment Anything Model (SAM) - The Foundation Model Era:**

```
    SEGMENT ANYTHING MODEL (SAM) - 2023
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Revolutionary: Promptable segmentation foundation model
    
    
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚            IMAGE ENCODER                â”‚
                     â”‚          (ViT-H/16 - HUGE)              â”‚
                     â”‚                                         â”‚
    Input Image â”€â”€â”€â”€â–ºâ”‚  Pre-compute once, reuse for all        â”‚
    (any size)       â”‚  prompts on same image                  â”‚
                     â”‚                                         â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                    Image Embedding
                                          â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚                                         â”‚
                     â”‚            PROMPT ENCODER               â”‚
                     â”‚                                         â”‚
    Prompts â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â€¢ Points (click positive/negative)     â”‚
    (flexible!)      â”‚  â€¢ Boxes (bounding box)                 â”‚
                     â”‚  â€¢ Masks (rough initial mask)           â”‚
                     â”‚  â€¢ Text (coming soon!)                  â”‚
                     â”‚                                         â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                   Prompt Embedding
                                          â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚                                         â”‚
                     â”‚          MASK DECODER                   â”‚
                     â”‚        (Lightweight!)                   â”‚
                     â”‚                                         â”‚
                     â”‚  Cross-attention between image &        â”‚
                     â”‚  prompt embeddings                      â”‚
                     â”‚                                         â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Output: 3 Masks     â”‚
                              â”‚   (multi-scale)       â”‚
                              â”‚   + Confidence scores â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    INTERACTIVE PROMPTING EXAMPLES:
    
    
    1. Point Prompt (click):
    
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚        â”‚   â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“       â”‚
       â”‚         â€¢           â”‚   â”€â”€â–º  â”‚  â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“      â”‚
       â”‚       (click)       â”‚        â”‚   â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“       â”‚
       â”‚                     â”‚        â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    2. Box Prompt:
    
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚        â”‚   â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“        â”‚
       â”‚   â”‚   ROI   â”‚       â”‚   â”€â”€â–º  â”‚  â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“       â”‚
       â”‚   â”‚         â”‚       â”‚        â”‚   â–“â–“â–“â–“â–“â–“â–“â–“â–“         â”‚
       â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚        â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    3. Positive + Negative Points:
    
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚        â€¢âº           â”‚        â”‚   â–“â–“â–“â–“â–“â–“â–“           â”‚
       â”‚      Tumor          â”‚   â”€â”€â–º  â”‚  â–“â–“â–“â–“â–“â–“â–“â–“           â”‚
       â”‚        â€¢â»           â”‚        â”‚   â–“â–“â–“â–“â–“â–“            â”‚
       â”‚      Vessel         â”‚        â”‚   (excludes vessel) â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ“Š Era 7: nnU-Net â€” The Self-Configuring Champion (2021)

**The most practical breakthrough for medical imaging**

```
    nnU-NET: "no-new-Net"
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Philosophy: Instead of novel architectures, 
                focus on OPTIMAL CONFIGURATION of existing methods
    
    
    INPUT: Your medical imaging dataset
           (any modality, any anatomy)
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     AUTOMATIC ANALYSIS                                  â”‚
    â”‚                                                                         â”‚
    â”‚  â€¢ Image dimensions & spacing                                           â”‚
    â”‚  â€¢ Intensity distribution                                               â”‚
    â”‚  â€¢ Class imbalance                                                      â”‚
    â”‚  â€¢ Dataset size                                                         â”‚
    â”‚  â€¢ Available GPU memory                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   AUTO-CONFIGURATION                                    â”‚
    â”‚                                                                         â”‚
    â”‚  Determines automatically:                                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚ â€¢ Preprocessing (resampling, normalization, cropping)              â”‚ â”‚
    â”‚  â”‚ â€¢ Network topology (2D, 3D, cascade)                               â”‚ â”‚
    â”‚  â”‚ â€¢ Patch size & batch size                                          â”‚ â”‚
    â”‚  â”‚ â€¢ Loss function (Dice + CE)                                        â”‚ â”‚
    â”‚  â”‚ â€¢ Data augmentation strategy                                       â”‚ â”‚
    â”‚  â”‚ â€¢ Learning rate schedule                                           â”‚ â”‚
    â”‚  â”‚ â€¢ Postprocessing                                                   â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                      TRAINING PIPELINE                                  â”‚
    â”‚                                                                         â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚    â”‚   2D U-Net  â”‚   â”‚  3D U-Net   â”‚   â”‚  3D Cascade â”‚                  â”‚
    â”‚    â”‚  (fullres)  â”‚   â”‚  (lowres)   â”‚   â”‚   U-Net     â”‚                  â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â”‚
    â”‚           â”‚                 â”‚                 â”‚                         â”‚
    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
    â”‚                             â”‚                                           â”‚
    â”‚                             â–¼                                           â”‚
    â”‚                      5-Fold Cross-Validation                            â”‚
    â”‚                             â”‚                                           â”‚
    â”‚                             â–¼                                           â”‚
    â”‚                    Model Ensemble + Selection                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    OUTPUT: Optimized model for YOUR specific dataset
            (often wins segmentation challenges!)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ¥ Medical Imaging Segmentation Applications

```
    SEGMENTATION IN RADIOLOGY: REAL-WORLD APPLICATIONS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    1. ORGAN SEGMENTATION (Multi-organ CT/MRI)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚         CT Abdomen                  â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
       â”‚    â”‚  â–“â–“â–“â–“ Liver      â”‚             â”‚    Applications:
       â”‚    â”‚    â–‘â–‘ Spleen     â”‚             â”‚    â€¢ Surgical planning
       â”‚    â”‚  â–ˆâ–ˆâ–ˆâ–ˆ Kidneys    â”‚             â”‚    â€¢ Radiation therapy
       â”‚    â”‚   â–’â–’ Pancreas    â”‚             â”‚    â€¢ Organ volumetrics
       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
       Best Models: nnU-Net, UNETR, Swin-UNETR
    
    
    2. TUMOR SEGMENTATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
       Brain MRI (Glioblastoma):
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                     â”‚
       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚    Regions:
       â”‚      â”‚   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘    â”‚              â”‚    â–‘ Edema
       â”‚      â”‚  â–‘â–‘â–“â–“â–“â–“â–‘â–‘â–‘    â”‚              â”‚    â–“ Enhancing tumor
       â”‚      â”‚  â–‘â–‘â–“â–ˆâ–ˆâ–“â–‘â–‘â–‘    â”‚              â”‚    â–ˆ Necrotic core
       â”‚      â”‚  â–‘â–‘â–“â–“â–“â–“â–‘â–‘â–‘    â”‚              â”‚
       â”‚      â”‚   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘    â”‚              â”‚
       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
       â”‚                                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
       Challenge: BraTS (Brain Tumor Segmentation)
       Best Models: nnU-Net, TransBTS, Swin-UNETR
    
    
    3. CARDIAC SEGMENTATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
       Cardiac MRI (Cine):
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                     â”‚
       â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
       â”‚         â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚             â”‚    Structures:
       â”‚        â•±â”‚ â–‘â–‘â–‘â–“â–“â–“â–“â–‘â–‘â–‘â–‘â”‚â•²             â”‚    â–‘ Right Ventricle
       â”‚       â•± â”‚ â–‘â–‘â–“â–“â–ˆâ–ˆâ–“â–“â–‘â–‘â–‘â”‚ â•²            â”‚    â–“ Myocardium
       â”‚       â•² â”‚ â–‘â–‘â–‘â–“â–“â–“â–“â–‘â–‘â–‘â–‘â”‚ â•±            â”‚    â–ˆ Left Ventricle
       â”‚        â•²â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚â•±             â”‚
       â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
       â”‚                                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
       Metrics: Ejection fraction, wall motion
       Best Models: U-Net, nnU-Net, Attention U-Net
    
    
    4. LUNG SEGMENTATION (COVID-19)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
       Chest CT:
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                     â”‚
       â”‚     â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”         â”‚
       â”‚    â•± â–‘â–‘â–‘â–‘â–‘ â•²       â•± â–‘â–‘â–‘â–‘â–‘ â•²        â”‚    Segments:
       â”‚   â”‚ â–‘â–‘â–“â–“â–‘â–‘â–‘ â”‚     â”‚ â–‘â–‘â–‘â–“â–“â–‘ â”‚        â”‚    â–‘ Normal lung
       â”‚   â”‚ â–‘â–‘â–“â–“â–“â–‘â–‘ â”‚     â”‚ â–‘â–“â–“â–“â–‘â–‘ â”‚        â”‚    â–“ Ground-glass
       â”‚   â”‚ â–‘â–‘â–‘â–“â–‘â–‘â–‘ â”‚     â”‚ â–‘â–‘â–‘â–‘â–‘â–‘ â”‚        â”‚      opacity (GGO)
       â”‚    â•² â–‘â–‘â–‘â–‘â–‘ â•±       â•² â–‘â–‘â–‘â–‘â–‘ â•±        â”‚
       â”‚     â””â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”˜         â”‚
       â”‚                                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
       Challenge: COVID-19 severity scoring
       Best Models: U-Net variants, Inf-Net
    
    
    5. RETINAL VESSEL SEGMENTATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
       Fundus Image:
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚            â•±â”€â”€â”€â”€â”€â”€â•²                 â”‚
       â”‚          â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²               â”‚
       â”‚         â”‚  â•â•â•â•â•â•â•   â”‚              â”‚    Structures:
       â”‚         â”‚ â•â•â•â—â•â•â•    â”‚              â”‚    â• Vessels
       â”‚         â”‚  â•â•â•â•â•â•â•   â”‚              â”‚    â— Optic disc
       â”‚          â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•±               â”‚
       â”‚            â•²â”€â”€â”€â”€â”€â”€â•±                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
       Applications: Diabetic retinopathy screening
       Best Models: U-Net, CE-Net, SA-UNet
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ“ˆ Summary Timeline

```
    EVOLUTION OF SEGMENTATION MODELS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    PRE-DEEP LEARNING
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1970s â”€â”€â—â”€â”€ Thresholding, Region Growing
            â”‚
    1990s â”€â”€â—â”€â”€ Active Contours (Snakes)
            â”‚
    2000s â”€â”€â—â”€â”€ Random Forests, CRF
            â”‚
    
    DEEP LEARNING ERA
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    2014  â”€â”€â—â”€â”€ FCN (Fully Convolutional Networks)
            â”‚   First end-to-end deep segmentation
            â”‚
    2015  â”€â”€â—â”€â”€ U-Net â˜… GAME CHANGER for Medical Imaging
            â”‚   Encoder-decoder with skip connections
            â”‚
    2016  â”€â”€â—â”€â”€ V-Net (3D), DeepLab v2 (Atrous convolutions)
            â”‚
    2017  â”€â”€â—â”€â”€ Mask R-CNN (Instance segmentation)
            â”‚   DeepLab v3+ (ASPP)
            â”‚
    2018  â”€â”€â—â”€â”€ Attention U-Net
            â”‚   UNet++ (Nested U-Net)
            â”‚
    2020  â”€â”€â—â”€â”€ SETR, TransUNet
            â”‚   Transformers enter segmentation
            â”‚
    2021  â”€â”€â—â”€â”€ nnU-Net â˜… Self-configuring, wins challenges
            â”‚   Swin-UNETR
            â”‚
    2022  â”€â”€â—â”€â”€ SegFormer, MedNeXt
            â”‚
    2023  â”€â”€â—â”€â”€ SAM (Segment Anything Model) â˜… Foundation model
            â”‚   MedSAM (Medical adaptation)
            â”‚
    2024+ â”€â—â”€â”€ Specialist medical foundation models
            â”‚   Multi-modal segmentation
            â–¼
         Present
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ¯ Practical Recommendations for Radiology AI

```
    WHICH MODEL TO USE? (2024 Guidelines)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    TASK                          RECOMMENDED MODEL           NOTES
    â”€â”€â”€â”€                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€
    
    Starting a new project        nnU-Net                     â€¢ Self-configuring
    (any modality)                                            â€¢ Strong baseline
                                                              â€¢ Easy to use
    
    2D segmentation               Standard U-Net              â€¢ Simple, proven
    (X-ray, fundus)               or U-Net++                  â€¢ Fast training
    
    3D volumetric                 nnU-Net or                  â€¢ Memory efficient
    (CT, MRI)                     Swin-UNETR                  â€¢ State-of-the-art
    
    Interactive segmentation      SAM / MedSAM                â€¢ Promptable
    (assisted annotation)                                     â€¢ Zero-shot capable
    
    Instance segmentation         Mask R-CNN or               â€¢ Multi-lesion
    (multiple lesions)            nnDetection                 â€¢ Tracking capable
    
    Limited training data         Transfer learning +         â€¢ Pre-trained weights
                                  Data augmentation           â€¢ Synthetic data
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    
    PRACTICAL WORKFLOW (How I'd start a project):
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. Start with nnU-Net
       â”‚
       â”‚  If it works well â†’ DONE! âœ“
       â”‚
       â–¼
    2. If need improvement:
       â”‚
       â”œâ”€â”€â–º Try different architectures (UNETR, Swin-UNETR)
       â”‚
       â”œâ”€â”€â–º Add attention mechanisms
       â”‚
       â””â”€â”€â–º Ensemble methods
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```


## ğŸ”§ PyTorch Libraries for Medical Segmentation

| Library | Description | Best For |
|---------|-------------|----------|
| **MONAI** | PyTorch framework for medical imaging | Full pipeline development |
| **nnU-Net** | Self-configuring segmentation | Out-of-box performance |
| **segmentation_models_pytorch** | Pre-built architectures | Quick prototyping |
| **TorchIO** | Medical image transforms | Data augmentation |
